{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-09-20T16:54:32.645301Z",
     "start_time": "2023-09-20T16:54:31.855285Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from pymdp.envs import TMazeEnv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-20T16:54:32.662445Z",
     "start_time": "2023-09-20T16:54:32.646633Z"
    }
   },
   "id": "3565b7eb36b2ffd8"
  },
  {
   "cell_type": "markdown",
   "source": [
    "*actions*: 0: CENTER, 1: RIGHT ARM, 2: LEFT ARM, 3: CUE LOCATION (bottom)\n",
    "\n",
    "*observations*: 0: LOCATION, 1: REWARD, 2: CUE\n",
    "\n",
    "*states*: 0: LOCATION, 1: CONTEXT"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "22c473c9f48c8bf4"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "env = TMazeEnv(reward_probs=[0.98, 0.02])\n",
    "A = env.get_likelihood_dist()\n",
    "B = env.get_transition_dist()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-20T16:54:32.676682Z",
     "start_time": "2023-09-20T16:54:32.663556Z"
    }
   },
   "id": "4c73ec1f10952b64"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "# Beliefs over the states: p(location), p(context)\n",
    "D = [np.array([1,0,0,0]),     # Knows it is in the center\n",
    "     np.array([0.5, 0.5])]    # but doesn't know the context ('reward condition')\n",
    "# Preferences over the observations: \\tilde p(Location), \\tilde p(reward), \\tilde(context)\n",
    "C = [np.array([0., 0., 0., 0.]), # Location: Doesn't matter where it is\n",
    "     np.array([ 0., 3., -3.]),   # Reward: Prefers to see reward than no reward, or punishment\n",
    "     np.array([0., 0.])]         # Cue: Doesn't matter the cue (right, left)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-20T16:54:32.690406Z",
     "start_time": "2023-09-20T16:54:32.678142Z"
    }
   },
   "id": "65633756507022d6"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "[0, 0, 0]"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obs = env.reset() # reset the environment and get an initial observation\n",
    "obs # Location, reward, cue"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-20T16:54:32.705982Z",
     "start_time": "2023-09-20T16:54:32.691592Z"
    }
   },
   "id": "81cb6e76f93e74ac"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "def softmax(dist):\n",
    "    \"\"\" \n",
    "    Computes the softmax function on a set of values\n",
    "    \"\"\"\n",
    "\n",
    "    output = dist - dist.max(axis=0)\n",
    "    output = np.exp(output)\n",
    "    output = output / np.sum(output, axis=0)\n",
    "    return output"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-20T16:54:32.718947Z",
     "start_time": "2023-09-20T16:54:32.705273Z"
    }
   },
   "id": "adfe4a720e4ca08a"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "# PYMDP nomenclature:\n",
    "# n_factor: number of dimension of a state\n",
    "# n_modality: number of dimension of an observation"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-20T16:54:32.735545Z",
     "start_time": "2023-09-20T16:54:32.719088Z"
    }
   },
   "id": "c66151f70de7d6e9"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "free energy:  0.6931471805599451\n"
     ]
    }
   ],
   "source": [
    "EPS = 1e-16\n",
    "\n",
    "# s_location_idx = 0\n",
    "# s_context_idx = 1\n",
    "# qs_context = D[s_context_idx] # Equals D for the first iteration\n",
    "n_dim_state = len(B)  # Location, context\n",
    "\n",
    "# Observe that they are in the center, that there is no reward, and that the cue is on the right\n",
    "obs = [np.array([1., 0., 0., 0.]), np.array([1., 0., 0.]), np.array([1., 0.])]\n",
    "\n",
    "dim_state = A[0].shape[1:]\n",
    "# Note that A[1].shape[1:] == A[2].shape[1:] == A[3].shape[1:] == dim_state\n",
    "# In this example, dim_state = (4, 2) \n",
    "# because state is defined by two factors, location and context, and there is 4 locations and 2 contexts\n",
    "n_uniq_state = np.prod(dim_state)\n",
    "# Note that np.prod(A[0].shape[1:]) == np.prod(A[i].shape[1:]) for all possible i\n",
    "likelihood = np.ones(n_uniq_state)\n",
    "for i in range(len(A)): \n",
    "    likelihood *= A[i].reshape(A[i].shape[0], n_uniq_state).T.dot(obs[i])\n",
    "\n",
    "likelihood = likelihood.reshape(*dim_state)\n",
    "log_likelihood = np.log(likelihood+EPS)\n",
    "\n",
    "# ------------------------------\n",
    "\n",
    "curr_iter = 0\n",
    "num_iter = 10\n",
    "dF = 1\n",
    "dF_tol = 0.001\n",
    "\n",
    "\n",
    "old_qs = D  # Init posterior, after first iteration, this will be the posterior from the previous timestep\n",
    "\n",
    "prior = []\n",
    "qs = []  # Init posterior\n",
    "\n",
    "for i in range(n_dim_state):\n",
    "    prior_i = np.log(old_qs[i] + EPS)\n",
    "    prior.append(prior_i)\n",
    "    qs.append(np.ones(len(prior_i)) / len(prior_i))\n",
    "    \n",
    "old_vfe = np.inf  # Init free energy, after first iteration, this will be the free energy from the previous iteration\n",
    "\n",
    "free_energy = None \n",
    "    \n",
    "while curr_iter < num_iter+1 and dF >= dF_tol:\n",
    "    \n",
    "    free_energy = 0\n",
    "    \n",
    "    # Following PYMDP, what follows is not done at the first computation of the VFE (called pre-vfe)\n",
    "    # Note that in PYMDP, the code is structured diferrently and this first computation is done BEFORE the main loop \n",
    "    # Here, to avoid copy-pasting the code, we refactored such that this is done at the iteration 0, and we continue \n",
    "    # one iteration more (hence, the '+1' in 'curr_iter < num_iter+1') \n",
    "    if curr_iter > 0:\n",
    "        # ================================================================\n",
    "        # Estimate q(s) for the current iteration \n",
    "        # --------------------------------------------------------------\n",
    "        # As according to equation B5 (p 245 in the book) q(s) = sigma(v)\n",
    "        # and v ~ - F\n",
    "        # We follow equation B4 (p 245 in the book) that gives a definition of F\n",
    "        # Note #1: as doing only one step ahead, we need to use a forward-only message passing technique only (as in \n",
    "        # https://doi.org/10.1162/NECO_a_00912)\n",
    "        ll_tensor = np.outer(*qs)*log_likelihood\n",
    "        for i in range(n_dim_state):\n",
    "            # Note #2: Sum over all the dimension of the state (\"factor\") except the one under consideration (dimension \n",
    "            # `i`)\n",
    "            ll_i = np.einsum(ll_tensor, np.arange(n_dim_state), [i])\n",
    "            # Rigorosly following the book, it should be\n",
    "            # v = ll_i - np.log(ps[i]) + prior[i]\n",
    "            # as per, per B4 and B5,  v = - ln(s) + ln(A) . o + ln(D)\n",
    "            v = ll_i / qs[i] + prior[i]\n",
    "            # Equation B.5 (first line)\n",
    "            qs[i] = softmax(v)\n",
    "            \n",
    "        # ================================================================\n",
    "        # Computing part of VFE (Following again Equation B4)\n",
    "        # => s . (ln(A) . o) \n",
    "        # equiv. to E_Q(s) P(o | s) in Eq B2\n",
    "        # ---------------------------------------------------------------\n",
    "        # meaning that \n",
    "        accuracy = np.sum(np.outer(*qs) * log_likelihood)\n",
    "        free_energy -= accuracy\n",
    "\n",
    "    # -------------------------------------------------------------------------------------\n",
    "\n",
    "    for i in range(n_dim_state):\n",
    "        \n",
    "        # Equation B.4 (simplified as we only look one step ahead, and distributing s_\\pi) \n",
    "        # (implementation of B2)\n",
    "        \n",
    "        # s . ln(s)\n",
    "        # equiv. to E_Q(s) (ln Q(s)) in equation B.2\n",
    "        # that is the negative entropy of the posterior marginal H(Q(s))\n",
    "        negH_qs = qs[i].dot(np.log(qs[i] + 1e-16))\n",
    "        \n",
    "        # s . ln(D) or if t > 0: s . ln(s_{t-1})\n",
    "        # that is the cross entropy of posterior marginal with prior marginal H(Q(s),P(s))\n",
    "        xH_qp = -qs[i].dot(prior[i])\n",
    "        \n",
    "        free_energy += negH_qs + xH_qp\n",
    "    \n",
    "    dF = np.abs(free_energy - old_vfe)\n",
    "    old_vfe = free_energy\n",
    "    curr_iter += 1\n",
    "print(\"free energy: \", free_energy)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-20T16:54:32.752398Z",
     "start_time": "2023-09-20T16:54:32.736633Z"
    }
   },
   "id": "2d119b6e6ef754c9"
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "2"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_dim_state"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-20T16:54:32.782084Z",
     "start_time": "2023-09-20T16:54:32.751321Z"
    }
   },
   "id": "74b568559ce30e9d"
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "data": {
      "text/plain": "(4, 2)"
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dim_state"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-20T13:30:42.098004Z",
     "start_time": "2023-09-20T13:30:42.079774Z"
    }
   },
   "id": "1bc053467a2de5a7"
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "data": {
      "text/plain": "(4, 4, 2)"
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A[0].shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-20T13:30:42.638553Z",
     "start_time": "2023-09-20T13:30:42.624149Z"
    }
   },
   "id": "6db1b42fc74b81ff"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "922c12d75d1a0acb"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
